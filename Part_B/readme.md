
# Bengali Transliteration without Attention Mechanism

This project implements a character-level Seq2Seq model for transliterating words from Latin script (English) to Bengali script using the Dakshina dataset. The model is trained **without an attention mechanism** and optimized using a hyperparameter sweep with **Weights & Biases (Wandb)**.

---

## ğŸ”§ Overview

- **Dataset**: Dakshina (Bengali)
- **Task**: Transliteration (Latin â†’ Bengali)
- **Model**: Encoderâ€“Decoder (RNN/GRU/LSTM)
- **Framework**: PyTorch
- **Evaluation**: Sequence accuracy on test set
- **Hardware**: Kaggle with GPU (if available)

---

## ğŸ“ Project Structure

```
without_attention/
â”œâ”€â”€ train_loader.py           # Script to run Wandb sweep
â”œâ”€â”€ train_evaluate.py         # Train & evaluate with best hyperparameters
â”œâ”€â”€ test_evaluator.py         # Final evaluation and prediction generation
â”œâ”€â”€ predictions_vanilla/      # Saved predictions (TSV)
â”œâ”€â”€ best_model.pt             # Saved model checkpoint
â””â”€â”€ README.md                 # This documentation
```

---

## ğŸ“¦ Dataset

**Path on Kaggle**:  
`/kaggle/input/dakshina/dakshina_dataset_v1.0/bn/lexicons/`

| File | Purpose |
|------|---------|
| `bn.translit.sampled.train.tsv` | Training set |
| `bn.translit.sampled.dev.tsv`   | Validation set |
| `bn.translit.sampled.test.tsv`  | Test set |

- Each file is tab-separated with two columns:
  - Column 1: Target word (Bengali)
  - Column 2: Source word (Latin)

---

## ğŸ§  Model Architecture

### ğŸ”¹ Encoder
- Input: Latin character sequence
- Embedding layer: `embedding_dim`
- RNN: `RNN`, `GRU`, or `LSTM` with `hidden_size` and `num_layers`
- Dropout: Applied after embedding and between layers

### ğŸ”¹ Decoder
- Input: Encoderâ€™s final hidden state + target (for teacher forcing)
- Embedding â†’ RNN â†’ Linear â†’ Log-Softmax
- Dropout applied similarly

### ğŸ”¹ Seq2Seq
- Combines Encoder and Decoder
- Training uses **teacher forcing**
- Inference uses **beam search** (or greedy decoding)

---

## âš™ï¸ Setup

### âœ… Prerequisites

- Environment: Kaggle notebook with GPU
- Install:
  ```bash
  pip install torch pandas wandb tqdm
  ```

- Wandb:
  ```bash
  wandb login
  ```

- Dataset should be available in the given Kaggle directory.

---

## ğŸ§ª Hyperparameter Sweep

### ğŸ” Method: Bayesian Optimization (`method: 'bayes'`)

**Sweep Search Space (defined in `train_loader.py`):**
```python
{
  emb_dim: [64, 128, 256],
  hidden_dim: [128, 256],
  enc_layers: [1, 2, 3],
  dec_layers: [1, 2, 3],
  cell_type: ['LSTM', 'GRU', 'RNN'],
  dropout: [0.2, 0.3, 0.4],
  batch_size: [32, 64, 128],
  learning_rate: [0.001, 0.0005, 0.0001],
  teacher_forcing: [0.5, 0.7, 0.9],
  beam_size: [1, 3, 5],
  patience: 3,
  epochs: [10, 15]
}
```

### ğŸ“ˆ Observations

- **GRU** consistently outperformed other RNN cells
- **RNN** often failed (<5% accuracy)
- Best batch sizes: **32 or 64**
- Optimal dropout: **0.2â€“0.4**
- **Beam size = 1** worked best (greedy decoding)
- Teacher Forcing: **0.5â€“0.9** was effective

---

## ğŸ† Best Hyperparameters

From `train_evaluate.py`:

```python
config = {
    'emb_dim': 128,
    'hidden_dim': 256,
    'enc_layers': 2,
    'dec_layers': 3,
    'cell_type': 'GRU',
    'dropout': 0.4,
    'batch_size': 64,
    'learning_rate': 0.0005,
    'teacher_forcing': 0.7,
    'beam_size': 1,
    'epochs': 10,
    'patience': 3
}
```

---

## ğŸ‹ï¸ Training

- **Script**: `train_evaluate.py`
- **Trainer class** handles model training and validation
- **Early stopping** with patience = 3
- Model saved to: `/kaggle/working/best_model.pt`
- Metrics logged to **Wandb**:
  - `train_loss`, `val_loss`
  - `token_accuracy`, `sequence_accuracy`

---

## ğŸ§¾ Evaluation

- **Script**: `test_evaluator.py`
- Loads best model and evaluates on the test set
- Predictions saved to: `predictions_vanilla/predictions.tsv`
- Displays **35 random samples** with color-coded backgrounds:
  - âœ… Correct: Green (`#90EE90`)
  - âŒ Incorrect: Pink (`#FFB6C1`)

---

## ğŸ¯ Results

| Metric              | Value (approx.) |
|---------------------|-----------------|
| Val Sequence Accuracy | ~40â€“50%         |
| Test Sequence Accuracy | ~35â€“45%         |

### ğŸ” Observations
- Struggles with complex vowel signs and conjuncts
- Performance limited by **lack of attention mechanism**

---

## ğŸ“Œ How to Use

1. **Create Kaggle notebook**
2. **Install dependencies and login to Wandb**
3. **Run sweep**:
   ```bash
   python train_loader.py
   ```
4. **Train & evaluate best config**:
   ```bash
   python train_evaluate.py
   ```
5. **Evaluate on test set**:
   ```bash
   python test_evaluator.py
   ```

---

## âš ï¸ Limitations

- No attention â†’ performance drop on longer sequences
- Cannot learn fine-grained alignments (e.g., vowel diacritics, conjunct clusters)

---

## ğŸ“‚ Output

- `best_model.pt`: Trained model checkpoint
- `predictions.tsv`: Full test predictions
- 35 highlighted samples for qualitative evaluation
