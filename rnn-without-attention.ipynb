{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":3485474,"sourceType":"datasetVersion","datasetId":2097669}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Necssary libary","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.nn.utils.rnn import pad_sequence\nimport pandas as pd\nimport unicodedata\nimport torch.optim as optim\nfrom tqdm import tqdm\nimport wandb\nimport pandas as pd\nimport random","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T15:34:20.308334Z","iopub.execute_input":"2025-05-20T15:34:20.308584Z","iopub.status.idle":"2025-05-20T15:34:26.984879Z","shell.execute_reply.started":"2025-05-20T15:34:20.308565Z","shell.execute_reply":"2025-05-20T15:34:26.984328Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# path for folders","metadata":{}},{"cell_type":"code","source":"train_path = '/kaggle/input/dakshina/dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.train.tsv'\nvalid_path = '/kaggle/input/dakshina/dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.dev.tsv'\ntest_path  = '/kaggle/input/dakshina/dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.test.tsv'\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T15:34:26.985954Z","iopub.execute_input":"2025-05-20T15:34:26.986404Z","iopub.status.idle":"2025-05-20T15:34:26.989922Z","shell.execute_reply.started":"2025-05-20T15:34:26.986375Z","shell.execute_reply":"2025-05-20T15:34:26.989319Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import wandb\nwandb.login(key=\"594642013968a68e466138e783dcece6765c43b9\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T15:34:29.062250Z","iopub.execute_input":"2025-05-20T15:34:29.062508Z","iopub.status.idle":"2025-05-20T15:34:35.426970Z","shell.execute_reply.started":"2025-05-20T15:34:29.062489Z","shell.execute_reply":"2025-05-20T15:34:35.426454Z"}},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mbgorai005\u001b[0m (\u001b[33mbgorai005-iit-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"# Encoder, decoder and seq2seq model class","metadata":{}},{"cell_type":"code","source":"class Encoder(nn.Module):\n    def __init__(self, input_size, embedding_dim, hidden_size, num_layers=1, cell_type='LSTM', dropout=0.2):\n        super(Encoder, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.cell_type = cell_type\n        self.embedding = nn.Embedding(input_size, embedding_dim)\n        rnn_class = {'RNN': nn.RNN, 'LSTM': nn.LSTM, 'GRU': nn.GRU}[cell_type]\n        self.rnn = rnn_class(\n            input_size=embedding_dim,\n            hidden_size=hidden_size,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout=dropout if num_layers > 1 else 0\n        )\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, input_seq):\n        embedded = self.dropout(self.embedding(input_seq))\n        batch_size = input_seq.size(0)\n        device = input_seq.device\n        if self.cell_type == 'LSTM':\n            hidden = (torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device),\n                     torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device))\n        else:\n            hidden = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n        output, hidden = self.rnn(embedded, hidden)\n        return output, hidden\n\nclass Decoder(nn.Module):\n    def __init__(self, output_size, embedding_dim, hidden_size, num_layers=1, cell_type='LSTM', dropout=0.2):\n        super(Decoder, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.cell_type = cell_type\n        self.embedding = nn.Embedding(output_size, embedding_dim)\n        rnn_class = {'RNN': nn.RNN, 'LSTM': nn.LSTM, 'GRU': nn.GRU}[cell_type]\n        self.rnn = rnn_class(\n            input_size=embedding_dim,\n            hidden_size=hidden_size,\n            num_layers=num_layers,\n            batch_first=True,\n            dropout=dropout if num_layers > 1 else 0\n        )\n        self.out = nn.Linear(hidden_size, output_size)\n        self.dropout = nn.Dropout(dropout)\n        self.softmax = nn.LogSoftmax(dim=-1)\n\n    def forward(self, input_char, hidden):\n        embedded = self.dropout(self.embedding(input_char))\n        output, hidden = self.rnn(embedded, hidden)\n        output = self.softmax(self.out(output.squeeze(1)))\n        return output, hidden\n\nclass Seq2Seq(nn.Module):\n    def __init__(self, encoder, decoder):\n        super(Seq2Seq, self).__init__()\n        self.encoder = encoder\n        self.decoder = decoder\n\n    def forward(self, source, target, teacher_forcing_ratio=0.5):\n        batch_size = source.size(0)\n        target_len = target.size(1)\n        target_vocab_size = self.decoder.embedding.num_embeddings\n        device = source.device\n        outputs = torch.zeros(batch_size, target_len, target_vocab_size).to(device)\n        _, hidden = self.encoder(source)\n        if self.encoder.num_layers != self.decoder.num_layers:\n            if self.encoder.cell_type == 'LSTM':\n                h_n, c_n = hidden\n                if self.decoder.num_layers > self.encoder.num_layers:\n                    extra_layers = self.decoder.num_layers - self.encoder.num_layers\n                    extra_h = torch.zeros(extra_layers, batch_size, self.decoder.hidden_size).to(device)\n                    extra_c = torch.zeros(extra_layers, batch_size, self.decoder.hidden_size).to(device)\n                    h_n = torch.cat([h_n, extra_h], dim=0)\n                    c_n = torch.cat([c_n, extra_c], dim=0)\n                else:\n                    h_n = h_n[:self.decoder.num_layers]\n                    c_n = c_n[:self.decoder.num_layers]\n                hidden = (h_n, c_n)\n            else:\n                if self.decoder.num_layers > self.encoder.num_layers:\n                    extra_layers = self.decoder.num_layers - self.encoder.num_layers\n                    extra_h = torch.zeros(extra_layers, batch_size, self.decoder.hidden_size).to(device)\n                    hidden = torch.cat([hidden, extra_h], dim=0)\n                else:\n                    hidden = hidden[:self.decoder.num_layers]\n        decoder_input = target[:, 0].unsqueeze(1)\n        for t in range(1, target_len):\n            output, hidden = self.decoder(decoder_input, hidden)\n            outputs[:, t] = output\n            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n            top1 = output.argmax(1)\n            decoder_input = target[:, t].unsqueeze(1) if teacher_force else top1.unsqueeze(1)\n        return outputs\n\n    def predict(self, src, max_len=30, beam_size=3):\n        self.eval()\n        batch_size = src.size(0)\n        device = src.device\n        _, hidden = self.encoder(src)\n        outputs = []\n        for i in range(batch_size):\n            if self.encoder.cell_type == 'LSTM':\n                h = hidden[0][:, i:i+1].contiguous()\n                c = hidden[1][:, i:i+1].contiguous()\n                hidden_state = (h, c)\n            else:\n                hidden_state = hidden[:, i:i+1].contiguous()\n            if self.encoder.num_layers != self.decoder.num_layers:\n                if self.encoder.cell_type == 'LSTM':\n                    h_n, c_n = hidden_state\n                    if self.decoder.num_layers > self.encoder.num_layers:\n                        extra_layers = self.decoder.num_layers - self.encoder.num_layers\n                        extra_h = torch.zeros(extra_layers, 1, self.decoder.hidden_size).to(device)\n                        extra_c = torch.zeros(extra_layers, 1, self.decoder.hidden_size).to(device)\n                        h_n = torch.cat([h_n, extra_h], dim=0)\n                        c_n = torch.cat([c_n, extra_c], dim=0)\n                    else:\n                        h_n = h_n[:self.decoder.num_layers]\n                        c_n = c_n[:self.decoder.num_layers]\n                    hidden_state = (h_n, c_n)\n                else:\n                    if self.decoder.num_layers > self.encoder.num_layers:\n                        extra_layers = self.decoder.num_layers - self.encoder.num_layers\n                        extra_h = torch.zeros(extra_layers, 1, self.decoder.hidden_size).to(device)\n                        hidden_state = torch.cat([hidden_state, extra_h], dim=0)\n                    else:\n                        hidden_state = hidden_state[:self.decoder.num_layers]\n            beams = [(torch.tensor([1], device=device), 0.0, hidden_state)]  # [sequence, score, hidden]\n            for _ in range(max_len):\n                new_beams = []\n                for seq, score, h in beams:\n                    input_char = seq[-1].unsqueeze(0).unsqueeze(0)\n                    output, h_new = self.decoder(input_char, h)\n                    probs = torch.log_softmax(output, dim=-1).squeeze(0)\n                    topk = torch.topk(probs, beam_size)\n                    for idx, prob in zip(topk.indices, topk.values):\n                        new_seq = torch.cat([seq, idx.unsqueeze(0)])\n                        new_score = score + prob.item()\n                        if self.decoder.cell_type == 'LSTM':\n                            h_new = (h_new[0].contiguous(), h_new[1].contiguous())\n                        else:\n                            h_new = h_new.contiguous()\n                        new_beams.append((new_seq, new_score, h_new))\n                beams = sorted(new_beams, key=lambda x: x[1], reverse=True)[:beam_size]\n                if beams[0][0][-1].item() == 2:  # Stop if <EOS>\n                    break\n            outputs.append(beams[0][0][1:])  # Exclude <SOS>\n        return outputs\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T15:34:41.376622Z","iopub.execute_input":"2025-05-20T15:34:41.377356Z","iopub.status.idle":"2025-05-20T15:34:41.398709Z","shell.execute_reply.started":"2025-05-20T15:34:41.377330Z","shell.execute_reply":"2025-05-20T15:34:41.398086Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"# data prepration class ","metadata":{}},{"cell_type":"code","source":"class DataPreprocessor:\n    def __init__(self, batch_size=32, device='cpu'):\n        self.batch_size = batch_size\n        self.device = device\n        self.src_vocab = None\n        self.tgt_vocab = None\n        self.PAD_TOKEN = '<PAD>'\n        self.SOS_TOKEN = '<SOS>'\n        self.EOS_TOKEN = '<EOS>'\n        self.UNK_TOKEN = '<UNK>'\n        self.PAD_IDX = 0\n        self.SOS_IDX = 1\n        self.EOS_IDX = 2\n        self.UNK_IDX = 3\n\n    def normalize_string(self, s):\n        s = unicodedata.normalize('NFC', str(s))\n        if all(ord(c) < 128 for c in s):\n            s = ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n            s = s.lower()\n        return s.strip()\n\n    def load_dataset(self, file_path=None, data_frame=None):\n        if file_path:\n            try:\n                data = pd.read_csv(file_path, sep='\\t', header=None)\n            except:\n                data = pd.read_csv(file_path, header=None)\n        elif data_frame is not None:\n            data = data_frame.copy()\n        else:\n            raise ValueError(\"Either file_path or data_frame must be provided.\")\n        data = data.rename(columns={0: 'tgt', 1: 'src'})\n        data['src'] = data['src'].apply(self.normalize_string)\n        data['tgt'] = data['tgt'].apply(self.normalize_string)\n        return data\n\n    def create_vocab(self, data, column):\n        vocab = {self.PAD_TOKEN: self.PAD_IDX, self.SOS_TOKEN: self.SOS_IDX,\n                 self.EOS_TOKEN: self.EOS_IDX, self.UNK_TOKEN: self.UNK_IDX}\n        for seq in data[column]:\n            if pd.notna(seq):\n                for char in seq:\n                    if char not in vocab:\n                        vocab[char] = len(vocab)\n        return vocab\n\n    def build_vocabularies(self, train_data):\n        self.src_vocab = self.create_vocab(train_data, 'src')\n        self.tgt_vocab = self.create_vocab(train_data, 'tgt')\n        return self.src_vocab, self.tgt_vocab\n\n    class TranslationDataset(Dataset):\n        def __init__(self, data, input_vocab, output_vocab):\n            self.data = data\n            self.input_vocab = input_vocab\n            self.output_vocab = output_vocab\n\n        def __len__(self):\n            return len(self.data)\n\n        def __getitem__(self, idx):\n            src = [self.input_vocab.get(c, self.input_vocab['<UNK>']) for c in self.data.iloc[idx, 1]] + [self.input_vocab['<EOS>']]\n            tgt = [self.output_vocab['<SOS>']] + [self.output_vocab.get(c, self.output_vocab['<UNK>']) for c in self.data.iloc[idx, 0]] + [self.output_vocab['<EOS>']]\n            src_str = self.data.iloc[idx, 1]\n            tgt_str = self.data.iloc[idx, 0]\n            return torch.tensor(src, dtype=torch.long), torch.tensor(tgt, dtype=torch.long), src_str, tgt_str\n\n    def pad_collate(self, batch):\n        src_batch, tgt_batch, src_strs, tgt_strs = zip(*batch)\n        src_padded = pad_sequence(src_batch, batch_first=True, padding_value=self.PAD_IDX)\n        tgt_padded = pad_sequence(tgt_batch, batch_first=True, padding_value=self.PAD_IDX)\n        return src_padded, tgt_padded, list(src_strs), list(tgt_strs)\n\n    def prepare_data(self, train_data, val_data, test_data):\n        if self.src_vocab is None or self.tgt_vocab is None:\n            self.build_vocabularies(train_data)\n        train_dataset = self.TranslationDataset(train_data, self.src_vocab, self.tgt_vocab)\n        val_dataset = self.TranslationDataset(val_data, self.src_vocab, self.tgt_vocab)\n        test_dataset = self.TranslationDataset(test_data, self.src_vocab, self.tgt_vocab)\n        train_loader = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True,\n                                 collate_fn=self.pad_collate, pin_memory=True)\n        val_loader = DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False,\n                                collate_fn=self.pad_collate, pin_memory=True)\n        test_loader = DataLoader(test_dataset, batch_size=self.batch_size, shuffle=False,\n                                 collate_fn=self.pad_collate, pin_memory=True)\n        return train_loader, val_loader, test_loader\nimport torch\nimport torch.nn as nn\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T15:34:48.196099Z","iopub.execute_input":"2025-05-20T15:34:48.196831Z","iopub.status.idle":"2025-05-20T15:34:48.210071Z","shell.execute_reply.started":"2025-05-20T15:34:48.196806Z","shell.execute_reply":"2025-05-20T15:34:48.209513Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# train class ","metadata":{}},{"cell_type":"code","source":"class Trainer:\n    def __init__(self, model, train_loader, val_loader, config, device='cpu', save_path='best_model.pt'):\n        self.model = model.to(device)\n        self.train_loader = train_loader\n        self.val_loader = val_loader\n        \n        self.device = device\n        self.config = config\n        self.teacher_forcing_ratio = config.teacher_forcing\n        self.num_epochs = config.epochs\n        self.save_path = save_path\n        self.criterion = nn.CrossEntropyLoss(ignore_index=0)  # Changed to CrossEntropyLoss\n        self.optimizer = optim.Adam(self.model.parameters(), lr=config.learning_rate)\n        self.src_vocab = None  # To store vocab for predictions\n        self.tgt_vocab = None\n\n    def compute_token_accuracy(self, outputs, targets):\n        \"\"\"Compute token-level accuracy.\"\"\"\n        outputs = outputs.argmax(dim=-1)  # [batch_size, seq_len]\n        non_pad_mask = (targets != 0) & (targets != 1) & (targets != 2)  # Exclude <PAD>, <SOS>, <EOS>\n        correct = (outputs == targets) & non_pad_mask\n        total = non_pad_mask.sum().item()\n        correct = correct.sum().item()\n        return correct / total if total > 0 else 0.0\n\n    def compute_sequence_accuracy(self, outputs, targets):\n        \"\"\"Compute sequence-level accuracy.\"\"\"\n        outputs = outputs.argmax(dim=-1)  # [batch_size, seq_len]\n        correct = 0\n        total = outputs.size(0)\n        for pred, tgt in zip(outputs, targets):\n            # Compare sequences, ignoring <PAD>, <SOS>, <EOS>\n            pred = pred[(tgt != 0) & (tgt != 1) & (tgt != 2)]\n            tgt = tgt[(tgt != 0) & (tgt != 1) & (tgt != 2)]\n            if torch.equal(pred, tgt):\n                correct += 1\n        return correct / total if total > 0 else 0.0\n\n    def train_epoch(self):\n        self.model.train()\n        total_loss, total_token_acc, total_seq_acc, total_samples = 0.0, 0.0, 0.0, 0\n\n        pbar = tqdm(self.train_loader, desc=\"Training\", leave=False)\n        for src, tgt, _, _ in pbar:  # Adjusted for src_strs, tgt_strs from DataLoader\n            src, tgt = src.to(self.device), tgt.to(self.device)\n            self.optimizer.zero_grad()\n\n            output = self.model(src, tgt, self.teacher_forcing_ratio)\n            output = output[:, 1:].contiguous().view(-1, output.size(-1))\n            tgt_flat = tgt[:, 1:].contiguous().view(-1)\n\n            loss = self.criterion(output, tgt_flat)\n            loss.backward()\n            self.optimizer.step()\n\n            batch_size = src.size(0)\n            token_acc = self.compute_token_accuracy(\n                output.view(batch_size, -1, output.size(-1)), tgt[:, 1:]\n            )\n            seq_acc = self.compute_sequence_accuracy(\n                output.view(batch_size, -1, output.size(-1)), tgt[:, 1:]\n            )\n\n            total_loss += loss.item() * batch_size\n            total_token_acc += token_acc * batch_size\n            total_seq_acc += seq_acc * batch_size\n            total_samples += batch_size\n\n            pbar.set_postfix(loss=loss.item(), token_acc=token_acc, seq_acc=seq_acc)\n\n        avg_loss = total_loss / total_samples\n        avg_token_acc = total_token_acc / total_samples\n        avg_seq_acc = total_seq_acc / total_samples\n        return avg_loss, avg_token_acc, avg_seq_acc\n\n    def evaluate(self, loader):\n        self.model.eval()\n        total_loss, total_token_acc, total_seq_acc, total_samples = 0.0, 0.0, 0.0, 0\n\n        pbar = tqdm(loader, desc=\"Evaluating\", leave=False)\n        with torch.no_grad():\n            for src, tgt, _, _ in pbar:\n                src, tgt = src.to(self.device), tgt.to(self.device)\n\n                output = self.model(src, tgt, teacher_forcing_ratio=0.0)\n                output = output[:, 1:].contiguous().view(-1, output.size(-1))\n                tgt_flat = tgt[:, 1:].contiguous().view(-1)\n\n                loss = self.criterion(output, tgt_flat)\n\n                batch_size = src.size(0)\n                token_acc = self.compute_token_accuracy(\n                    output.view(batch_size, -1, output.size(-1)), tgt[:, 1:]\n                )\n                seq_acc = self.compute_sequence_accuracy(\n                    output.view(batch_size, -1, output.size(-1)), tgt[:, 1:]\n                )\n\n                total_loss += loss.item() * batch_size\n                total_token_acc += token_acc * batch_size\n                total_seq_acc += seq_acc * batch_size\n                total_samples += batch_size\n\n                pbar.set_postfix(loss=loss.item(), token_acc=token_acc, seq_acc=seq_acc)\n\n        avg_loss = total_loss / total_samples\n        avg_token_acc = total_token_acc / total_samples\n        avg_seq_acc = total_seq_acc / total_samples\n        return avg_loss, avg_token_acc, avg_seq_acc\n\n    def train(self, src_vocab, tgt_vocab):\n        \"\"\"Train the model, logging metrics and predictions to Wandb.\"\"\"\n        self.src_vocab = src_vocab\n        self.tgt_vocab = tgt_vocab\n        best_val_seq_acc = 0.0\n        patience = getattr(self.config, 'patience', 3)\n        patience_counter = 0\n\n        for epoch in range(1, self.num_epochs + 1):\n            # Train\n            train_loss, train_token_acc, train_seq_acc = self.train_epoch()\n            # Evaluate\n            val_loss, val_token_acc, val_seq_acc = self.evaluate(self.val_loader)\n\n            # Print metrics\n            print(f'\\nEpoch {epoch}/{self.num_epochs}')\n            print(f'Train Loss: {train_loss:.4f} | Train Token Acc: {train_token_acc*100:.2f}% | Train Seq Acc: {train_seq_acc*100:.2f}%')\n            print(f'Val Loss:   {val_loss:.4f} | Val Token Acc:   {val_token_acc*100:.2f}% | Val Seq Acc:   {val_seq_acc*100:.2f}%')\n            print('-' * 60)\n\n            # Log metrics to Wandb\n            wandb.log({\n                'epoch': epoch,\n                'train_loss': train_loss,\n                 'val_loss': val_loss,\n                'train_token_accuracy': train_token_acc,\n                'val_token_accuracy': val_token_acc,\n                'train_sequence_accuracy': train_seq_acc,\n                'val_sequence_accuracy': val_seq_acc\n            })\n\n            # Log sample predictions\n            src_sample, tgt_sample, src_strs, tgt_strs = next(iter(self.val_loader))\n            src_sample = src_sample.to(self.device)\n            preds = self.model.predict(src_sample[:5], max_len=30, beam_size=self.config.beam_size)\n\n            inv_src_vocab = {v: k for k, v in src_vocab.items()}\n            inv_tgt_vocab = {v: k for k, v in tgt_vocab.items()}\n            table = wandb.Table(columns=[\"Input\", \"Target\", \"Prediction\"])\n            for i in range(len(preds)):\n                input_str = ''.join([inv_src_vocab.get(id.item(), '?') for id in src_sample[i] if id.item() not in [0, src_vocab['<EOS>']]])\n                target_str = ''.join([inv_tgt_vocab.get(id.item(), '?') for id in tgt_sample[i] if id.item() not in [0, tgt_vocab['<EOS>'], tgt_vocab['<SOS>']]])\n                pred_str = ''.join([inv_tgt_vocab.get(id.item(), '?') for id in preds[i] if id.item() not in [0, tgt_vocab['<EOS>']]])\n                table.add_data(input_str, target_str, pred_str)\n            wandb.log({\"predictions\": table})\n\n            # Early stopping and checkpoint\n            if val_seq_acc > best_val_seq_acc:\n                best_val_seq_acc = val_seq_acc\n                patience_counter = 0\n                torch.save(self.model.state_dict(), self.save_path)\n                print(f\"✅ New best model saved with val sequence accuracy: {val_seq_acc*100:.2f}%\")\n            else:\n                patience_counter += 1\n                print(f\"⚠️ No improvement. Patience counter: {patience_counter}/{patience}\")\n                if patience_counter >= patience:\n                    print(\" Early stopping triggered.\")\n                    break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T15:34:53.299975Z","iopub.execute_input":"2025-05-20T15:34:53.300759Z","iopub.status.idle":"2025-05-20T15:34:53.321943Z","shell.execute_reply.started":"2025-05-20T15:34:53.300733Z","shell.execute_reply":"2025-05-20T15:34:53.321359Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"# hyper parameter tuning for searching best hyperparamter","metadata":{}},{"cell_type":"code","source":"# Wandb sweep config\nsweep_config = {\n    'method': 'bayes',\n    'metric': {'name': 'val_sequence_accuracy', 'goal': 'maximize'},\n    'parameters': {\n        'emb_dim': {'values': [64, 128, 256]},\n        'hidden_dim': {'values': [128, 256]},\n        'enc_layers': {'values': [1, 2, 3]},\n        'dec_layers': {'values': [1, 2, 3]},\n        'cell_type': {'values': ['LSTM', 'GRU','RNN']},\n        'dropout': {'values': [0.2, 0.3, 0.4]},\n        'batch_size': {'values': [32, 64, 128]},\n        'learning_rate': {'values': [0.001, 0.0005, 0.0001]},\n        'teacher_forcing': {'values': [0.5, 0.7, 0.9]},\n        'beam_size': {'values': [1, 3, 5]},\n        'patience': {'value': 3},\n        'epochs': {'values': [10, 15]}\n    }\n}\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# train loader function to handle the sweep","metadata":{}},{"cell_type":"code","source":"import torch\nimport wandb\nimport pandas as pd\nimport os\n\ndef train_loader(\n    train_path='/kaggle/input/dakshina/dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.train.tsv',\n    valid_path='/kaggle/input/dakshina/dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.dev.tsv',\n    test_path='/kaggle/input/dakshina/dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.test.tsv',\n    device='cuda' if torch.cuda.is_available() else 'cpu',\n    save_path='/kaggle/working/best_model.pt'\n):\n    \"\"\"\n    Training function for running a WandB sweep on the Bengali Dakshina dataset.\n    \"\"\"\n    # Initialize WandB\n    wandb.init(project=\"assignment_3\")\n    # Shortcut to config\n    config = wandb.config\n\n    # Construct a descriptive run name\n    run_name = (\n        f\"-cell-{config.cell_type}\"\n        f\"embed-{config.emb_dim}\"\n        f\"-enc_layers-{config.enc_layers}\"\n        f\"-dec_layers-{config.dec_layers}\"\n        f\"-hid-{config.hidden_dim}\"\n       \n        f\"-dropout-{config.dropout}\"\n        f\"-bs-{config.batch_size}\"\n        f\"-lr-{config.learning_rate}\"\n        f\"-tf-{config.teacher_forcing}\"\n        f\"-beam-{config.beam_size}\"\n    )\n    wandb.run.name = run_name\n\n    \n    # Initialize DataPreprocessor\n    preprocessor = DataPreprocessor(batch_size=config.batch_size, device=device)\n\n    # Load datasets\n    train_data = preprocessor.load_dataset(train_path)\n    val_data = preprocessor.load_dataset(valid_path)\n    test_data = preprocessor.load_dataset(test_path)\n\n    # Prepare data loaders\n    train_loader, val_loader, test_loader = preprocessor.prepare_data(train_data, val_data, test_data)\n\n    # Initialize model\n    encoder = Encoder(\n        input_size=len(preprocessor.src_vocab),\n        embedding_dim=config.emb_dim,\n        hidden_size=config.hidden_dim,\n        num_layers=config.enc_layers,\n        cell_type=config.cell_type,\n        dropout=config.dropout\n    )\n    decoder = Decoder(\n        output_size=len(preprocessor.tgt_vocab),\n        embedding_dim=config.emb_dim,\n        hidden_size=config.hidden_dim,\n        num_layers=config.dec_layers,\n        cell_type=config.cell_type,\n        dropout=config.dropout\n    )\n    model = Seq2Seq(encoder, decoder).to(device)\n\n    # Initialize Trainer\n    trainer = Trainer(\n        model=model,\n        train_loader=train_loader,\n        val_loader=val_loader,\n        config=config,\n        device=device,\n        save_path=save_path\n    )\n\n    # Train with vocabularies\n    trainer.train(preprocessor.src_vocab, preprocessor.tgt_vocab)\n\n   \n    # Finish Wandb run\n    wandb.finish()\n\n\nif __name__ == \"__main__\":\n    sweep_id = wandb.sweep(sweep_config, project=\"assignment_3\")\n    wandb.agent(sweep_id, function=train_loader, count=10)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T06:19:44.521265Z","iopub.execute_input":"2025-05-20T06:19:44.521542Z","iopub.status.idle":"2025-05-20T06:20:14.312778Z","shell.execute_reply.started":"2025-05-20T06:19:44.521521Z","shell.execute_reply":"2025-05-20T06:20:14.311775Z"}},"outputs":[{"name":"stdout","text":"Create sweep with ID: bskdv1xl\nSweep URL: https://wandb.ai/bgorai005-iit-madras/assignment_3/sweeps/bskdv1xl\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: w2xdfoci with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 64\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_size: 5\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdec_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \temb_dim: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tenc_layers: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_dim: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.0005\n\u001b[34m\u001b[1mwandb\u001b[0m: \tpatience: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tteacher_forcing: 0.5\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Ignoring project 'assignment_3' when running a sweep."},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_061952-w2xdfoci</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/bgorai005-iit-madras/assignment_3/runs/w2xdfoci' target=\"_blank\">skilled-sweep-1</a></strong> to <a href='https://wandb.ai/bgorai005-iit-madras/assignment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/bgorai005-iit-madras/assignment_3/sweeps/bskdv1xl' target=\"_blank\">https://wandb.ai/bgorai005-iit-madras/assignment_3/sweeps/bskdv1xl</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/bgorai005-iit-madras/assignment_3' target=\"_blank\">https://wandb.ai/bgorai005-iit-madras/assignment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View sweep at <a href='https://wandb.ai/bgorai005-iit-madras/assignment_3/sweeps/bskdv1xl' target=\"_blank\">https://wandb.ai/bgorai005-iit-madras/assignment_3/sweeps/bskdv1xl</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/bgorai005-iit-madras/assignment_3/runs/w2xdfoci' target=\"_blank\">https://wandb.ai/bgorai005-iit-madras/assignment_3/runs/w2xdfoci</a>"},"metadata":{}},{"name":"stderr","text":"Training:  12%|█▏        | 179/1478 [00:11<01:17, 16.82it/s, loss=3.26, seq_acc=0, token_acc=0.118] \u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"import torch\nimport pandas as pd\nfrom tqdm import tqdm\nimport os\n\nclass TestEvaluator:\n    def __init__(self, model, test_loader, src_vocab, tgt_vocab, device='cuda' if torch.cuda.is_available() else 'cpu'):\n        self.model = model.to(device)\n        self.test_loader = test_loader\n        self.src_vocab = src_vocab\n        self.tgt_vocab = tgt_vocab\n        self.device = device\n        self.inv_src_vocab = {v: k for k, v in src_vocab.items()}\n        self.inv_tgt_vocab = {v: k for k, v in tgt_vocab.items()}\n    def check_model_file(self, model_path):\n        \"\"\"Check if the model file exists and provide guidance if it doesn't.\"\"\"\n        if not os.path.exists(model_path):\n            error_msg = f\"Error: Model file not found at '{model_path}'.\\n\"\n            error_msg += \"Possible solutions:\\n\"\n            error_msg += \"1. Ensure training completed successfully and saved the model to '/kaggle/working/best_model.pt'.\\n\"\n            error_msg += \"2. Check if the model was saved to a different path and update 'model_path'.\\n\"\n            error_msg += \"3. Rerun the training script to generate the model.\\n\"\n            error_msg += \"4. If running in Kaggle, verify that '/kaggle/working/' is accessible and the file was persisted.\\n\"\n            error_msg += \"5. Provide the correct path to an existing model file.\"\n            raise FileNotFoundError(error_msg)\n        print(f\"Model file found at '{model_path}'.\")\n    def compute_sequence_accuracy(self, outputs, targets):\n        \"\"\"Compute sequence-level accuracy (exact match, ignoring special tokens).\"\"\"\n        outputs = outputs.argmax(dim=-1)  # [batch_size, seq_len]\n        correct = 0\n        total = outputs.size(0)\n        for pred, tgt in zip(outputs, targets):\n            pred = pred[(tgt != 0) & (tgt != 1) & (tgt != 2)]  # Exclude <PAD>, <SOS>, <EOS>\n            tgt = tgt[(tgt != 0) & (tgt != 1) & (tgt != 2)]\n            if torch.equal(pred, tgt):\n                correct += 1\n        return correct / total if total > 0 else 0.0\n\n    def evaluate_test_set(self):\n        \"\"\"Evaluate the model on the test set and return sequence accuracy.\"\"\"\n        self.model.eval()\n        total_seq_acc, total_samples = 0.0, 0\n\n        with torch.no_grad():\n            for src, tgt, _, _ in tqdm(self.test_loader, desc=\"Evaluating Test Set\"):\n                src, tgt = src.to(self.device), tgt.to(self.device)\n                output = self.model(src, tgt, teacher_forcing_ratio=0.0)\n                output = output[:, 1:].contiguous()  # Exclude <SOS>\n                seq_acc = self.compute_sequence_accuracy(output, tgt[:, 1:])\n                batch_size = src.size(0)\n                total_seq_acc += seq_acc * batch_size\n                total_samples += batch_size\n\n        avg_seq_acc = total_seq_acc / total_samples\n        return avg_seq_acc\n\n    def generate_predictions(self, output_dir=\"predictions_vanilla\", num_samples=10):\n        \"\"\"Generate predictions for the test set and save them to a file. Return samples for display.\"\"\"\n        self.model.eval()\n        predictions = []\n        sample_data = []\n\n        os.makedirs(output_dir, exist_ok=True)\n        pred_file = os.path.join(output_dir, \"predictions.tsv\")\n\n        with torch.no_grad():\n            for src, tgt, src_strs, tgt_strs in tqdm(self.test_loader, desc=\"Generating Predictions\"):\n                src = src.to(self.device)\n                preds = self.model.predict(src, max_len=30, beam_size=3)  # Use beam_size=3 as default\n                for i in range(len(preds)):\n                    input_str = src_strs[i]\n                    target_str = tgt_strs[i]\n                    pred_ids = preds[i]\n                    pred_str = ''.join([self.inv_tgt_vocab.get(id.item(), '?') for id in pred_ids if id.item() not in [0, self.tgt_vocab['<EOS>']]])\n                    predictions.append((input_str, target_str, pred_str))\n                    if len(sample_data) < num_samples:\n                        sample_data.append((input_str, target_str, pred_str))\n\n        # Save all predictions to a TSV file\n        pred_df = pd.DataFrame(predictions, columns=[\"Input\", \"Target\", \"Prediction\"])\n        pred_df.to_csv(pred_file, sep='\\t', index=False)\n\n        return sample_data, pred_file\n\n    def display_samples(self, sample_data):\n        \"\"\"Format sample predictions as a markdown table.\"\"\"\n        markdown = \"| Input | Target | Prediction | Match |\\n\"\n        markdown += \"|-------|--------|------------|-------|\\n\"\n        for input_str, target_str, pred_str in sample_data:\n            match = \"✅\" if pred_str == target_str else \"❌\"\n            markdown += f\"| {input_str} | {target_str} | {pred_str} | {match} |\\n\"\n        return markdown\n\n    def display_samples_highlight_incorrect(self, sample_data):\n        \"\"\"Format sample predictions as a markdown table, highlighting incorrect predictions.\"\"\"\n        markdown = \"| Input | Target | Prediction | Match |\\n\"\n        markdown += \"|-------|--------|------------|-------|\\n\"\n        for input_str, target_str, pred_str in sample_data:\n            match = \"✅\" if pred_str == target_str else \"❌\"\n            display_pred = f\"**{pred_str}**\" if pred_str != target_str else pred_str\n            markdown += f\"| {input_str} | {target_str} | {display_pred} | {match} |\\n\"\n        return markdown","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T06:18:58.297312Z","iopub.execute_input":"2025-05-20T06:18:58.298040Z","iopub.status.idle":"2025-05-20T06:18:58.384663Z","shell.execute_reply.started":"2025-05-20T06:18:58.298011Z","shell.execute_reply":"2025-05-20T06:18:58.383919Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# class test evaluator","metadata":{}},{"cell_type":"code","source":"\nclass TestEvaluator:\n    def __init__(self, model, test_loader, src_vocab, tgt_vocab, device='cuda' if torch.cuda.is_available() else 'cpu'):\n        self.model = model.to(device)\n        self.test_loader = test_loader\n        self.src_vocab = src_vocab\n        self.tgt_vocab = tgt_vocab\n        self.device = device\n        self.inv_src_vocab = {v: k for k, v in src_vocab.items()}\n        self.inv_tgt_vocab = {v: k for k, v in tgt_vocab.items()}\n\n    def check_model_file(self, model_path):\n        \"\"\"Check if the model file exists and provide guidance if it doesn't.\"\"\"\n        if not os.path.exists(model_path):\n            error_msg = f\"Error: Model file not found at '{model_path}'.\\n\"\n            error_msg += \"Possible solutions:\\n\"\n            error_msg += \"1. Ensure training completed successfully and saved the model to '/kaggle/working/best_model.pt'.\\n\"\n            error_msg += \"2. Check if the model was saved to a different path and update 'model_path'.\\n\"\n            error_msg += \"3. Rerun the training script to generate the model.\\n\"\n            error_msg += \"4. If running in Kaggle, verify that '/kaggle/working/' is accessible and the file was persisted.\\n\"\n            error_msg += \"5. Provide the correct path to an existing model file.\"\n            raise FileNotFoundError(error_msg)\n        print(f\"Model file found at '{model_path}'.\")\n\n    def compute_sequence_accuracy(self, outputs, targets):\n        \"\"\"Compute sequence-level accuracy (exact match, ignoring special tokens).\"\"\"\n        outputs = outputs.argmax(dim=-1)  # [batch_size, seq_len]\n        correct = 0\n        total = outputs.size(0)\n        for pred, tgt in zip(outputs, targets):\n            pred = pred[(tgt != 0) & (tgt != 1) & (tgt != 2)]  # Exclude <PAD>, <SOS>, <EOS>\n            tgt = tgt[(tgt != 0) & (tgt != 1) & (tgt != 2)]\n            if torch.equal(pred, tgt):\n                correct += 1\n        return correct / total if total > 0 else 0.0\n\n    def evaluate_test_set(self):\n        \"\"\"Evaluate the model on the test set and return sequence accuracy.\"\"\"\n        self.model.eval()\n        total_seq_acc, total_samples = 0.0, 0\n\n        with torch.no_grad():\n            for src, tgt, _, _ in tqdm(self.test_loader, desc=\"Evaluating Test Set\"):\n                src, tgt = src.to(self.device), tgt.to(self.device)\n                output = self.model(src, tgt, teacher_forcing_ratio=0.0)\n                output = output[:, 1:].contiguous()  # Exclude <SOS>\n                seq_acc = self.compute_sequence_accuracy(output, tgt[:, 1:])\n                batch_size = src.size(0)\n                total_seq_acc += seq_acc * batch_size\n                total_samples += batch_size\n\n        avg_seq_acc = total_seq_acc / total_samples\n        return avg_seq_acc\n\n    def generate_predictions(self, output_dir=\"predictions     predictions_vanilla\", num_samples=35):\n        \"\"\"Generate predictions for the entire test set, save to a TSV file, and return a random sample of predictions.\"\"\"\n        self.model.eval()\n        predictions = []\n\n        os.makedirs(output_dir, exist_ok=True)\n        pred_file = os.path.join(output_dir, \"predictions.tsv\")\n\n        with torch.no_grad():\n            for src, tgt, src_strs, tgt_strs in tqdm(self.test_loader, desc=\"Generating Predictions\"):\n                src = src.to(self.device)\n                preds = self.model.predict(src, max_len=30, beam_size=3)  # Use beam_size=3 as default\n                for i in range(len(preds)):\n                    input_str = src_strs[i]\n                    target_str = tgt_strs[i]\n                    pred_ids = preds[i]\n                    pred_str = ''.join([self.inv_tgt_vocab.get(id.item(), '?') for id in pred_ids if id.item() not in [0, self.tgt_vocab['<EOS>']]])\n                    predictions.append((input_str, target_str, pred_str))\n\n        # Save all predictions to a TSV file\n        pred_df = pd.DataFrame(predictions, columns=[\"Input\", \"Target\", \"Prediction\"])\n        pred_df.to_csv(pred_file, sep='\\t', index=False)\n\n        # Select random samples\n        sample_data = random.sample(predictions, min(num_samples, len(predictions)))\n\n        return sample_data, pred_file\n\n    def format_sample_table(self, sample_data):\n        \"\"\"Format sample predictions as a markdown table with colored backgrounds.\"\"\"\n        markdown = \"| Input | Target | Prediction | Status |\\n\"\n        markdown += \"|-------|--------|------------|--------|\\n\"\n        for input_str, target_str, pred_str in sample_data:\n            is_correct = pred_str == target_str\n            bg_color = \"background-color: #90EE90\" if is_correct else \"background-color: #FFB6C1\"  # Green or Pink\n            markdown += f\"| {input_str} | {target_str} | <span style=\\\"{bg_color}\\\">{pred_str}</span> | {'Correct' if is_correct else 'Incorrect'} |\\n\"\n        return markdown\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T15:35:06.364520Z","iopub.execute_input":"2025-05-20T15:35:06.365227Z","iopub.status.idle":"2025-05-20T15:35:06.434000Z","shell.execute_reply.started":"2025-05-20T15:35:06.365203Z","shell.execute_reply":"2025-05-20T15:35:06.433385Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"# best hyper paramter","metadata":{}},{"cell_type":"code","source":"#best hyper parameter \n\n# batch_size:\n#     value: 32\n# beam_size:\n#     value: 3\n# cell_type:\n#     value: LSTM\n# dec_layers:\n#     value: 3\n# dropout:\n#     value: 0.3\n# emb_dim:\n#     value: 64\n# enc_layers:\n#     value: 3\n# epochs:\n#     value: 15\n# hidden_dim:\n#     value: 256\n# learning_rate:\n#     value: 0.0005\n# patience:\n#     value: 3\n# teacher_forcing:\n#     value: 0.7","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T07:36:40.868093Z","iopub.execute_input":"2025-05-20T07:36:40.868391Z","iopub.status.idle":"2025-05-20T07:36:40.874793Z","shell.execute_reply.started":"2025-05-20T07:36:40.868365Z","shell.execute_reply":"2025-05-20T07:36:40.874070Z"}},"outputs":[],"execution_count":1},{"cell_type":"markdown","source":"# train with best hyperparameter function ","metadata":{}},{"cell_type":"code","source":"import torch\nimport pandas as pd\nfrom tqdm import tqdm\nimport os\nimport wandb\nimport random\n\n\ndef train_with_best_hyperparams(\n    train_path='/kaggle/input/dakshina/dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.train.tsv',\n    valid_path='/kaggle/input/dakshina/dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.dev.tsv',\n    test_path='/kaggle/input/dakshina/dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.test.tsv',\n    device='cuda' if torch.cuda.is_available() else 'cpu',\n    save_path='/kaggle/working/best_model.pt'\n):\n    \"\"\"\n    Train the model with the best hyperparameters and save it to save_path.\n    Returns the trained model and vocabularies.\n    \"\"\"\n    # Best hyperparameters from WandB\n    config = {\n        'batch_size': 64,\n        'beam_size': 1,\n        'cell_type': 'GRU',\n        'dec_layers': 3,\n        'dropout': 0.4,\n        'emb_dim': 128,\n        'enc_layers': 2,\n        'epochs': 10,\n        'hidden_dim': 256,\n        'learning_rate': 0.0005,\n        'patience': 3,\n        'teacher_forcing': 0.7\n    }\n\n\n\n    # Convert config to an object for compatibility with Trainer\n    class Config:\n        def __init__(self, params):\n            for key, value in params.items():\n                setattr(self, key, value)\n    \n    config_obj = Config(config)\n\n    # Initialize WandB run\n    wandb.init(project=\"assignment_3\", config=config, name=\"best_hyperparams_run_vanilla\")\n    \n    # Initialize DataPreprocessor\n    preprocessor = DataPreprocessor(batch_size=config['batch_size'], device=device)\n    \n    # Load datasets\n    train_data = preprocessor.load_dataset(train_path)\n    val_data = preprocessor.load_dataset(valid_path)\n    test_data = preprocessor.load_dataset(test_path)\n    \n    # Prepare data loaders\n    train_loader, val_loader, test_loader = preprocessor.prepare_data(train_data, val_data, test_data)\n    \n    # Initialize model\n    encoder = Encoder(\n        input_size=len(preprocessor.src_vocab),\n        embedding_dim=config['emb_dim'],\n        hidden_size=config['hidden_dim'],\n        num_layers=config['enc_layers'],\n        cell_type=config['cell_type'],\n        dropout=config['dropout']\n    )\n    decoder = Decoder(\n        output_size=len(preprocessor.tgt_vocab),\n        embedding_dim=config['emb_dim'],\n        hidden_size=config['hidden_dim'],\n        num_layers=config['dec_layers'],\n        cell_type=config['cell_type'],\n        dropout=config['dropout']\n    )\n    model = Seq2Seq(encoder, decoder).to(device)\n    \n    # Initialize Trainer\n    trainer = Trainer(\n        model=model,\n        train_loader=train_loader,\n        val_loader=val_loader,\n        config=config_obj,\n        device=device,\n        save_path=save_path\n    )\n    \n    # Train the model\n    trainer.train(preprocessor.src_vocab, preprocessor.tgt_vocab)\n    \n    # Finish WandB run\n    wandb.finish()\n    \n    print(f\"Training completed. Model saved to {save_path}\")\n    return model, preprocessor.src_vocab, preprocessor.tgt_vocab, test_loader\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T15:37:18.660785Z","iopub.execute_input":"2025-05-20T15:37:18.661427Z","iopub.status.idle":"2025-05-20T15:37:18.670112Z","shell.execute_reply.started":"2025-05-20T15:37:18.661397Z","shell.execute_reply":"2025-05-20T15:37:18.669420Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"# function evaluting for best model","metadata":{}},{"cell_type":"code","source":"def evaluate_with_best_model(\n    model,\n    test_loader,\n    src_vocab,\n    tgt_vocab,\n    model_path='/kaggle/working/best_model.pt',\n    device='cuda' if torch.cuda.is_available() else 'cpu'\n):\n    \"\"\"\n    Evaluate the model on the test set and generate predictions with highlighted incorrect outputs.\n    Returns sequence accuracy, markdown table, and predictions file path.\n    \"\"\"\n    # Initialize TestEvaluator\n    evaluator = TestEvaluator(model, test_loader, src_vocab, tgt_vocab, device)\n    \n    # Check model file\n    evaluator.check_model_file(model_path)\n    \n    # Load the model (already loaded in model, but verify for consistency)\n    model.load_state_dict(torch.load(model_path, map_location=device))\n    print(f\"Loaded model from {model_path}\")\n    \n    # Evaluate on test set\n    test_seq_acc = evaluator.evaluate_test_set()\n    print(f\"\\nTest Set Sequence Accuracy: {test_seq_acc*100:.2f}%\")\n    \n    # Generate predictions\n    sample_data, pred_file = evaluator.generate_predictions(num_samples=30)\n    print(f\"\\nPredictions saved to {pred_file}\")\n    \n    # Display sample predictions with incorrect ones highlighted\n    markdown_table = evaluator.format_sample_table(sample_data)\n    print(\"\\nSample Predictions (Incorrect Predictions Highlighted):\")\n    print(markdown_table)\n    \n    return test_seq_acc, markdown_table, pred_file","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T15:37:23.908673Z","iopub.execute_input":"2025-05-20T15:37:23.908925Z","iopub.status.idle":"2025-05-20T15:37:23.914069Z","shell.execute_reply.started":"2025-05-20T15:37:23.908906Z","shell.execute_reply":"2025-05-20T15:37:23.913246Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"# main function for test set ","metadata":{}},{"cell_type":"code","source":"if __name__ == \"__main__\":\n    try:\n        # Train with best hyperparameters\n        model, src_vocab, tgt_vocab, test_loader = train_with_best_hyperparams()\n        \n        # Evaluate on test set\n        test_seq_acc, markdown_table, pred_file = evaluate_with_best_model(\n            model, test_loader, src_vocab, tgt_vocab\n        )\n    except FileNotFoundError as e:\n        print(e)\n    except Exception as e:\n        print(f\"Error during training or evaluation: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T15:37:28.168988Z","iopub.execute_input":"2025-05-20T15:37:28.169308Z","iopub.status.idle":"2025-05-20T15:54:43.289605Z","shell.execute_reply.started":"2025-05-20T15:37:28.169287Z","shell.execute_reply":"2025-05-20T15:54:43.288944Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_153728-j6uez7xt</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/bgorai005-iit-madras/assignment_3/runs/j6uez7xt' target=\"_blank\">best_hyperparams_run_vanilla</a></strong> to <a href='https://wandb.ai/bgorai005-iit-madras/assignment_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/bgorai005-iit-madras/assignment_3' target=\"_blank\">https://wandb.ai/bgorai005-iit-madras/assignment_3</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/bgorai005-iit-madras/assignment_3/runs/j6uez7xt' target=\"_blank\">https://wandb.ai/bgorai005-iit-madras/assignment_3/runs/j6uez7xt</a>"},"metadata":{}},{"name":"stderr","text":"                                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"\nEpoch 1/10\nTrain Loss: 1.9551 | Train Token Acc: 40.19% | Train Seq Acc: 3.50%\nVal Loss:   1.6544 | Val Token Acc:   51.66% | Val Seq Acc:   13.31%\n------------------------------------------------------------\n✅ New best model saved with val sequence accuracy: 13.31%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                          \r","output_type":"stream"},{"name":"stdout","text":"\nEpoch 2/10\nTrain Loss: 0.9289 | Train Token Acc: 69.65% | Train Seq Acc: 16.50%\nVal Loss:   1.4351 | Val Token Acc:   61.11% | Val Seq Acc:   24.66%\n------------------------------------------------------------\n✅ New best model saved with val sequence accuracy: 24.66%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                         \r","output_type":"stream"},{"name":"stdout","text":"\nEpoch 3/10\nTrain Loss: 0.7049 | Train Token Acc: 77.00% | Train Seq Acc: 25.73%\nVal Loss:   1.4084 | Val Token Acc:   64.10% | Val Seq Acc:   28.90%\n------------------------------------------------------------\n✅ New best model saved with val sequence accuracy: 28.90%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                         \r","output_type":"stream"},{"name":"stdout","text":"\nEpoch 4/10\nTrain Loss: 0.5961 | Train Token Acc: 80.64% | Train Seq Acc: 32.28%\nVal Loss:   1.3473 | Val Token Acc:   66.95% | Val Seq Acc:   31.87%\n------------------------------------------------------------\n✅ New best model saved with val sequence accuracy: 31.87%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                         \r","output_type":"stream"},{"name":"stdout","text":"\nEpoch 5/10\nTrain Loss: 0.5243 | Train Token Acc: 82.96% | Train Seq Acc: 37.13%\nVal Loss:   1.3000 | Val Token Acc:   68.93% | Val Seq Acc:   34.56%\n------------------------------------------------------------\n✅ New best model saved with val sequence accuracy: 34.56%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                         \r","output_type":"stream"},{"name":"stdout","text":"\nEpoch 6/10\nTrain Loss: 0.4741 | Train Token Acc: 84.65% | Train Seq Acc: 41.18%\nVal Loss:   1.2898 | Val Token Acc:   69.39% | Val Seq Acc:   35.78%\n------------------------------------------------------------\n✅ New best model saved with val sequence accuracy: 35.78%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                         \r","output_type":"stream"},{"name":"stdout","text":"\nEpoch 7/10\nTrain Loss: 0.4335 | Train Token Acc: 85.89% | Train Seq Acc: 43.99%\nVal Loss:   1.3150 | Val Token Acc:   69.38% | Val Seq Acc:   35.38%\n------------------------------------------------------------\n⚠️ No improvement. Patience counter: 1/3\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                         \r","output_type":"stream"},{"name":"stdout","text":"\nEpoch 8/10\nTrain Loss: 0.4053 | Train Token Acc: 86.86% | Train Seq Acc: 46.83%\nVal Loss:   1.3304 | Val Token Acc:   69.74% | Val Seq Acc:   36.25%\n------------------------------------------------------------\n✅ New best model saved with val sequence accuracy: 36.25%\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                         \r","output_type":"stream"},{"name":"stdout","text":"\nEpoch 9/10\nTrain Loss: 0.3810 | Train Token Acc: 87.64% | Train Seq Acc: 49.04%\nVal Loss:   1.3595 | Val Token Acc:   69.93% | Val Seq Acc:   35.68%\n------------------------------------------------------------\n","output_type":"stream"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Network error (HTTPError), entering retry loop.\n","output_type":"stream"},{"name":"stdout","text":"⚠️ No improvement. Patience counter: 1/3\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                         \r","output_type":"stream"},{"name":"stdout","text":"\nEpoch 10/10\nTrain Loss: 0.3590 | Train Token Acc: 88.40% | Train Seq Acc: 51.00%\nVal Loss:   1.3298 | Val Token Acc:   70.62% | Val Seq Acc:   37.31%\n------------------------------------------------------------\n✅ New best model saved with val sequence accuracy: 37.31%\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▃▃▄▅▆▆▇█</td></tr><tr><td>train_loss</td><td>█▃▃▂▂▂▁▁▁▁</td></tr><tr><td>train_sequence_accuracy</td><td>▁▃▄▅▆▇▇▇██</td></tr><tr><td>train_token_accuracy</td><td>▁▅▆▇▇▇████</td></tr><tr><td>val_loss</td><td>█▄▃▂▁▁▁▂▂▂</td></tr><tr><td>val_sequence_accuracy</td><td>▁▄▆▆▇█▇███</td></tr><tr><td>val_token_accuracy</td><td>▁▄▆▇▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>10</td></tr><tr><td>train_loss</td><td>0.35896</td></tr><tr><td>train_sequence_accuracy</td><td>0.51005</td></tr><tr><td>train_token_accuracy</td><td>0.88396</td></tr><tr><td>val_loss</td><td>1.32977</td></tr><tr><td>val_sequence_accuracy</td><td>0.3731</td></tr><tr><td>val_token_accuracy</td><td>0.70615</td></tr></table><br/></div></div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run <strong style=\"color:#cdcd00\">best_hyperparams_run_vanilla</strong> at: <a href='https://wandb.ai/bgorai005-iit-madras/assignment_3/runs/j6uez7xt' target=\"_blank\">https://wandb.ai/bgorai005-iit-madras/assignment_3/runs/j6uez7xt</a><br> View project at: <a href='https://wandb.ai/bgorai005-iit-madras/assignment_3' target=\"_blank\">https://wandb.ai/bgorai005-iit-madras/assignment_3</a><br>Synced 5 W&B file(s), 10 media file(s), 16 artifact file(s) and 0 other file(s)"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Find logs at: <code>./wandb/run-20250520_153728-j6uez7xt/logs</code>"},"metadata":{}},{"name":"stdout","text":"Training completed. Model saved to /kaggle/working/best_model.pt\nModel file found at '/kaggle/working/best_model.pt'.\nLoaded model from /kaggle/working/best_model.pt\n","output_type":"stream"},{"name":"stderr","text":"Evaluating Test Set: 100%|██████████| 145/145 [00:04<00:00, 35.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"\nTest Set Sequence Accuracy: 35.59%\n","output_type":"stream"},{"name":"stderr","text":"Generating Predictions: 100%|██████████| 145/145 [01:56<00:00,  1.25it/s]","output_type":"stream"},{"name":"stdout","text":"\nPredictions saved to predictions     predictions_vanilla/predictions.tsv\n\nSample Predictions (Incorrect Predictions Highlighted):\n| Input | Target | Prediction | Status |\n|-------|--------|------------|--------|\n| ranchi | রাঁচি | <span style=\"background-color: #FFB6C1\">রাঞ্চি</span> | Incorrect |\n| potel | পটেল | <span style=\"background-color: #FFB6C1\">পোটেল</span> | Incorrect |\n| bandhuraa | বন্ধুরা | <span style=\"background-color: #90EE90\">বন্ধুরা</span> | Correct |\n| met | মত | <span style=\"background-color: #FFB6C1\">মেট</span> | Incorrect |\n| baasati | বাসাটি | <span style=\"background-color: #90EE90\">বাসাটি</span> | Correct |\n| sikkhoker | শিক্ষকের | <span style=\"background-color: #90EE90\">শিক্ষকের</span> | Correct |\n| nirangkush | নিরঙ্কুশ | <span style=\"background-color: #FFB6C1\">নিরঙ্কুষ</span> | Incorrect |\n| pyada | প্যাড | <span style=\"background-color: #90EE90\">প্যাড</span> | Correct |\n| belphast | বেলফাস্ট | <span style=\"background-color: #90EE90\">বেলফাস্ট</span> | Correct |\n| ranotaree | রণতরী | <span style=\"background-color: #FFB6C1\">রানাটারী</span> | Incorrect |\n| ekkosee | এককোষী | <span style=\"background-color: #FFB6C1\">একোসি</span> | Incorrect |\n| jaahaner | জাহানের | <span style=\"background-color: #90EE90\">জাহানের</span> | Correct |\n| janosomaabesh | জনসমাবেশ | <span style=\"background-color: #FFB6C1\">জনসমাবেস</span> | Incorrect |\n| otyacharey | অত্যাচারে | <span style=\"background-color: #90EE90\">অত্যাচারে</span> | Correct |\n| lebhanta | লেভান্ট | <span style=\"background-color: #90EE90\">লেভান্ট</span> | Correct |\n| bitee | বিটি | <span style=\"background-color: #90EE90\">বিটি</span> | Correct |\n| upobas | উপবাস | <span style=\"background-color: #90EE90\">উপবাস</span> | Correct |\n| silmohar | সিলমোহর | <span style=\"background-color: #FFB6C1\">শিলমোহর</span> | Incorrect |\n| dhandhar | ধাঁধার | <span style=\"background-color: #FFB6C1\">ধানধার</span> | Incorrect |\n| shulka | শুল্ক | <span style=\"background-color: #FFB6C1\">শুলকা</span> | Incorrect |\n| tushtir | তুষ্টির | <span style=\"background-color: #FFB6C1\">তুস্টির</span> | Incorrect |\n| pala | পাল | <span style=\"background-color: #FFB6C1\">পালা</span> | Incorrect |\n| gitikabi | গীতিকবি | <span style=\"background-color: #FFB6C1\">গীতিকাবি</span> | Incorrect |\n| ssumishto | সুমিষ্ট | <span style=\"background-color: #90EE90\">সুমিষ্ট</span> | Correct |\n| shplintar | স্প্লিন্টার | <span style=\"background-color: #90EE90\">স্প্লিন্টার</span> | Correct |\n| oyeeka | ওয়েক | <span style=\"background-color: #90EE90\">ওয়েক</span> | Correct |\n| presidium | প্রেসিডিয়াম | <span style=\"background-color: #90EE90\">প্রেসিডিয়াম</span> | Correct |\n| khappare | খপ্পরে | <span style=\"background-color: #FFB6C1\">খাপপারে</span> | Incorrect |\n| baksaler | বাকশালের | <span style=\"background-color: #90EE90\">বাকশালের</span> | Correct |\n| egonor | এগোনোর | <span style=\"background-color: #FFB6C1\">এগনোর</span> | Incorrect |\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"import pandas as pd\n\n# Step 1: Load the TSV file into a DataFrame\ndf = pd.read_csv('/kaggle/working/predictions     predictions_vanilla/predictions.tsv', sep='\\t')\n\n# Step 2: Display the first 35 rows\nprint(df.head(35))\n\n# Step 3: Convert and save the DataFrame as a CSV file\ndf.to_csv('/kaggle/working/predictions     predictions_vanilla/predictions.tsv', index=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-20T07:26:53.142421Z","iopub.execute_input":"2025-05-20T07:26:53.142688Z","iopub.status.idle":"2025-05-20T07:26:53.180009Z","shell.execute_reply.started":"2025-05-20T07:26:53.142668Z","shell.execute_reply":"2025-05-20T07:26:53.179370Z"}},"outputs":[{"name":"stdout","text":"               Input        Target    Prediction\n0               anri          অঁরি      অ্যান্রি\n1              aunry          অঁরি        আউন্রি\n2               onry          অঁরি         অন্রি\n3                ori          অঁরি           ওরি\n4    angsagrohonkari  অংশগ্রহনকারী  অংশগ্রহণকারী\n5   angshogrohonkari  অংশগ্রহনকারী  অংশগ্রহণকারী\n6    angsogrohonkari  অংশগ্রহনকারী  অংশগ্রহণকারী\n7    anshograhankari  অংশগ্রহনকারী  অংশগ্রহণকারী\n8    ongsagrohonkari  অংশগ্রহনকারী  অংশগ্রহণকারী\n9   ongshogrohonkari  অংশগ্রহনকারী  অংশগ্রহণকারী\n10   ongsogrohonkari  অংশগ্রহনকারী  অংশগ্রহণকারী\n11        akkharguli     অক্ষরগুলি     আক্ষরগুলি\n12        akshorguli     অক্ষরগুলি     আক্ষরগুলি\n13         aksorguli     অক্ষরগুলি     আক্ষরগুলি\n14        okkhorguli     অক্ষরগুলি     অক্ষরগুলি\n15        okshorguli     অক্ষরগুলি     অক্ষরগুলি\n16         oksorguli     অক্ষরগুলি     অক্ষরগুলি\n17        akkhargulo     অক্ষরগুলো     আক্ষরগুলো\n18        akshorgulo     অক্ষরগুলো     আক্ষরগুলো\n19         aksorgulo     অক্ষরগুলো     আক্ষরগুলো\n20        okkhorgulo     অক্ষরগুলো     অক্ষরগুলো\n21        okshorgulo     অক্ষরগুলো     অক্ষরগুলো\n22         oksorgulo     অক্ষরগুলো     অক্ষরগুলো\n23          akkharti       অক্ষরটি       আক্ষরটি\n24          akkhorti       অক্ষরটি       আক্ষরটি\n25           aksarti       অক্ষরটি       একশ্রটি\n26           akkhare        অক্ষরে       অক্ষারে\n27          akkharey        অক্ষরে       অক্ষারে\n28           akkhore        অক্ষরে        আক্ষরে\n29          akkhorey        অক্ষরে        আক্ষরে\n30           okkhore        অক্ষরে        অক্ষরে\n31          akkharer       অক্ষরের      অক্ষারের\n32          akkhorer       অক্ষরের       অক্ষরের\n33          okkhorer       অক্ষরের       অক্ষরের\n34         aksaforda     অক্সফোর্ড     অক্সপোর্ড\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}